{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from collections import Counter\n",
    "from cycler import cycler\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"123\"))\n",
    "def down_sample(df):\n",
    "    copy = df.copy()\n",
    "    zero = Counter(copy.label.values)[0]\n",
    "    un = Counter(copy.label.values)[1]\n",
    "    n = zero - un\n",
    "    copy = copy.drop(copy[copy.label == 0].sample(n=n, random_state=1).index)\n",
    "    return copy.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1329|\n",
      "|    1| 1329|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find positive examples\n",
    "train_existing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)-[:Interacts_early]->(b:Character)\n",
    "RETURN id(a) AS node1, id(b) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()# Find negative examples\n",
    "train_missing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)\n",
    "WHERE (a)-[:Interacts_early]-()\n",
    "MATCH (a)-[:Interacts_early*2..3]-(other)\n",
    "WHERE not((a)-[:Interacts_early]-(other))\n",
    "RETURN id(a) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()# Remove duplicates\n",
    "train_missing_links = train_missing_links.drop_duplicates()\n",
    "training_df = train_missing_links.append(train_existing_links, ignore_index=True)\n",
    "training_df['label'] = training_df['label'].astype('category')\n",
    "training_df = down_sample(training_df)\n",
    "training_data = spark.createDataFrame(training_df)\n",
    "\n",
    "test_existing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)-[:Interacts_late]->(b:Character)\n",
    "RETURN id(a) AS node1, id(b) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()# Find negative examples\n",
    "test_missing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)\n",
    "WHERE (a)-[:Interacts_late]-()\n",
    "MATCH (a)-[:Interacts_late*2..3]-(other)\n",
    "WHERE not((a)-[:Interacts_late]-(other))\n",
    "RETURN id(a) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()# Remove duplicates\n",
    "test_missing_links = test_missing_links.drop_duplicates()\n",
    "test_df = test_missing_links.append(test_existing_links, ignore_index=True)\n",
    "test_df['label'] = test_df['label'].astype('category')\n",
    "test_df = down_sample(test_df)\n",
    "test_data = spark.createDataFrame(test_df)\n",
    "\n",
    "test_data.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(fields):\n",
    "    assembler = VectorAssembler(inputCols=fields, outputCol=\"features\")\n",
    "    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",\n",
    "                                numTrees=30, maxDepth=10)\n",
    "    return Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_graphy_training_features(data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    size([(p1)-[:Interacts_early]-(a)-\n",
    "    [:Interacts_early]-(p2) | a]) AS CommonInteractions,\n",
    "    size((p1)-[:Interacts_early]-()) * size((p2)-\n",
    "    [:Interacts_early]-()) AS prefAttachment,\n",
    "    size(apoc.coll.toSet(\n",
    "    [(p1)-[:Interacts_early]-(a) | id(a)] +\n",
    "    [(p2)-[:Interacts_early]-(a) | id(a)]\n",
    "    )) AS totalNeighbors\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "    for row in data.collect()]\n",
    "    features = spark.createDataFrame(graph.run(query,\n",
    "                                               {\"pairs\": pairs}).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "def apply_graphy_test_features(data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    size([(p1)-[:Interacts]-(a)-[:Interacts]-(p2) | a]) AS CommonInteractions,\n",
    "    size((p1)-[:Interacts]-()) * size((p2)-[:Interacts]-())\n",
    "    AS prefAttachment,\n",
    "    size(apoc.coll.toSet(\n",
    "    [(p1)-[:Interacts]-(a) | id(a)] + [(p2)-[:Interacts]-(a) | id(a)]\n",
    "    )) AS totalNeighbors\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "    for row in data.collect()]\n",
    "    features = spark.createDataFrame(graph.run(query,\n",
    "                                               {\"pairs\": pairs}).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "\n",
    "training_data = apply_graphy_training_features(training_data)\n",
    "test_data = apply_graphy_test_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 7), sharey=True)\n",
    "charts = [(1, \"have interacted\"), (0, \"haven't interacted\")]\n",
    "for index, chart in enumerate(charts):\n",
    "    label, title = chart\n",
    "    filtered = training_data.filter(training_data[\"label\"] == label)\n",
    "    interactions = filtered.toPandas()[\"CommonInteractions\"]\n",
    "    histogram =interactions.value_counts().sort_index()\n",
    "    histogram /= float(histogram.sum())\n",
    "    histogram.plot(kind=\"bar\", x='Common Interactions', color=\"darkblue\",\n",
    "    ax=axs[index], title=f\"Character who {title} (label={label})\")\n",
    "    axs[index].xaxis.set_label_text(\"Common Interactions\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of model\n",
    "\n",
    "Here is a basic model based on common interactions in order to predict the future interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------+----------+\n",
      "|CommonInteractions|probability                             |prediction|\n",
      "+------------------+----------------------------------------+----------+\n",
      "|0                 |[0.8213024551457555,0.17869754485424455]|0.0       |\n",
      "|1                 |[0.8213024551457555,0.17869754485424455]|0.0       |\n",
      "|2                 |[0.09791873796806792,0.9020812620319322]|1.0       |\n",
      "|10                |[0.09791873796806792,0.9020812620319322]|1.0       |\n",
      "|100               |[0.09791873796806792,0.9020812620319322]|1.0       |\n",
      "+------------------+----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(fields, training_data):\n",
    "    pipeline = create_pipeline(fields)\n",
    "    model = pipeline.fit(training_data)\n",
    "    return model\n",
    "\n",
    "basic_model = train_model([\"CommonInteractions\"], training_data)\n",
    "\n",
    "eval_df = spark.createDataFrame(\n",
    "        [(0,), (1,), (2,), (10,), (100,)],\n",
    "        ['CommonInteractions'])\n",
    "\n",
    "\n",
    "(basic_model.transform(eval_df)\n",
    "    .select(\"CommonInteractions\", \"probability\", \"prediction\")\n",
    "    .show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    # Execute the model against the test set\n",
    "    predictions = model.transform(test_data)\n",
    "    # Compute true positive, false positive, false negative counts\n",
    "    tp = predictions[(predictions.label == 1) &\n",
    "        (predictions.prediction == 1)].count()\n",
    "    fp = predictions[(predictions.label == 0) &\n",
    "                     (predictions.prediction == 1)].count()\n",
    "    fn = predictions[(predictions.label == 1) &\n",
    "                     (predictions.prediction == 0)].count()\n",
    "    # Compute recall and precision manually\n",
    "    recall = float(tp) / (tp + fn)\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    # Compute accuracy using Spark MLLib's binary classification evaluator\n",
    "    accuracy = BinaryClassificationEvaluator().evaluate(predictions)\n",
    "    # Compute false positive rate and true positive rate using sklearn functions\n",
    "    labels = [row[\"label\"] for row in predictions.select(\"label\").collect()]\n",
    "    preds = [row[\"probability\"][1] for row in predictions.select\n",
    "             (\"probability\").collect()]\n",
    "    fpr, tpr, threshold = roc_curve(labels, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return { \"fpr\": fpr, \"tpr\": tpr, \"roc_auc\": roc_auc, \"accuracy\": accuracy,\n",
    "            \"recall\": recall, \"precision\": precision }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.806245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.765237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.833607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measure     Score\n",
       "0   accuracy  0.806245\n",
       "1     recall  0.765237\n",
       "2  precision  0.833607"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_results(results):\n",
    "    results = {k: v for k, v in results.items() if k not in [\"fpr\", \"tpr\", \"roc_auc\"]}\n",
    "    return pd.DataFrame({\"Measure\": list(results.keys()),\n",
    "                         \"Score\": list(results.values())})\n",
    "\n",
    "basic_results = evaluate_model(basic_model, test_data)\n",
    "display_results(basic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_plot():\n",
    "    plt.style.use('classic')\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.rc('axes', prop_cycle=(cycler('color',\n",
    "                                      ['r', 'g', 'b', 'c', 'm', 'y', 'k'])))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random score (AUC = 0.50)')\n",
    "    return plt, fig\n",
    "\n",
    "def add_curve(plt, title, fpr, tpr, roc):\n",
    "    plt.plot(fpr, tpr, label=f\"{title} (AUC = {roc:0.2})\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",basic_results[\"fpr\"], basic_results[\"tpr\"], basic_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|CommonInteractions|    prefAttachment|    totalNeighbors|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              1849|              1849|              1849|\n",
      "|   mean| 6.472147106544078| 649.0016224986479|  47.7658193618172|\n",
      "| stddev| 6.590397693758528|1042.7011892287317|31.153957172436126|\n",
      "|    min|                 0|                 2|                 3|\n",
      "|    max|                49|              7968|               159|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|CommonInteractions|   prefAttachment|    totalNeighbors|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|              1849|             1849|              1849|\n",
      "|   mean|0.4402379664683613|61.00378583017847| 17.35803136830719|\n",
      "| stddev|0.9955654637902858|127.8862940523298|17.254947581369585|\n",
      "|    min|                 0|                1|                 1|\n",
      "|    max|                14|             2190|               102|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(training_data.filter(training_data[\"label\"]==1)\n",
    "    .describe()\n",
    "    .select(\"summary\", \"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\")\n",
    "    .show())\n",
    "(training_data.filter(training_data[\"label\"]==0)\n",
    "    .describe()\n",
    "    .select(\"summary\", \"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\")\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex model with 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.884213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.808126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.811178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measure     Score\n",
       "0   accuracy  0.884213\n",
       "1     recall  0.808126\n",
       "2  precision  0.811178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [\"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\"]\n",
    "graphy_model = train_model(fields, training_data)\n",
    "\n",
    "graphy_results = evaluate_model(graphy_model, test_data)\n",
    "display_results(graphy_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",\n",
    "          basic_results[\"fpr\"], basic_results[\"tpr\"],\n",
    "                              basic_results[\"roc_auc\"])\n",
    "add_curve(plt, \"Graphy\",\n",
    "          graphy_results[\"fpr\"], graphy_results[\"tpr\"],\n",
    "          graphy_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which features are important ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(fields, feature_importances):\n",
    "    df = pd.DataFrame({\"Feature\": fields, \"Importance\": feature_importances})\n",
    "    df = df.sort_values(\"Importance\", ascending=False)\n",
    "    ax = df.plot(kind='bar', x='Feature', y='Importance', legend=None)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = graphy_model.stages[-1]\n",
    "plot_feature_importance(fields, rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a decision tree (WIP package on jupyter...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from spark_tree_plotting import export_graphviz\\ndot_string = export_graphviz(rf_model.trees[0],\\n                             featureNames=fields, categoryNames=[], classNames=[\"True\", \"False\"],\\n                             filled=True, roundedCorners=True, roundLeaves=True)\\nwith open(\"/tmp/rf.dot\", \"w\") as file:\\n    file.write(dot_string)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from spark_tree_plotting import export_graphviz\n",
    "dot_string = export_graphviz(rf_model.trees[0],\n",
    "                             featureNames=fields, categoryNames=[], classNames=[\"True\", \"False\"],\n",
    "                             filled=True, roundedCorners=True, roundLeaves=True)\n",
    "with open(\"/tmp/rf.dot\", \"w\") as file:\n",
    "    file.write(dot_string)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new features: triangle and clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to call some functions in Neo4j.\n",
    "\n",
    "```cypher\n",
    "call gds.graph.create(\"G\",\"Character\",\n",
    "{\n",
    "\tInteracts : {\n",
    "    \ttype:\"Interacts\",\n",
    "        properties: 'weight',\n",
    "        orientation:'UNDIRECTED'\n",
    "    }\n",
    "    })\n",
    "```\n",
    "    \n",
    "```cypher\n",
    "CALL gds.triangleCount.write(\"G\", {\n",
    "writeProperty:'trianglesTest'})\n",
    "```\n",
    "```cypher\n",
    "CALL gds.localClusteringCoefficient.write(\"G\", {\n",
    "writeProperty:'coefficientTest'})\n",
    "```\n",
    "\n",
    "\n",
    "```cypher\n",
    "call gds.graph.create(\"G_ea\",\"Character\",\n",
    "{\n",
    "\tInteracts_early : {\n",
    "    \ttype:\"Interacts_early\",\n",
    "        properties: 'weight',\n",
    "        orientation:'UNDIRECTED'\n",
    "    }\n",
    "    })\n",
    "```\n",
    "\n",
    "```cypher\n",
    "CALL gds.triangleCount.write(\"G_ea\", {\n",
    "writeProperty:'trianglesTrain'})\n",
    "```\n",
    "\n",
    "```cypher\n",
    "CALL gds.localClusteringCoefficient.write(\"G\", {\n",
    "writeProperty:'coefficientTrain'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_triangles_features(data, triangles_prop, coefficient_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "            pair.node2 AS node2,\n",
    "            apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]])\n",
    "            AS minTriangles,\n",
    "            apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]])\n",
    "            AS maxTriangles,\n",
    "            apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]])\n",
    "            AS minCoefficient,\n",
    "            apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]])\n",
    "            AS maxCoefficient\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"pairs\": [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "                            for row in data.collect()],\n",
    "        \"trianglesProp\": triangles_prop,\n",
    "        \"coefficientProp\": coefficient_prop\n",
    "    }\n",
    "    features = spark.createDataFrame(graph.run(query, params).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "training_data = apply_triangles_features(training_data, \"trianglesTrain\", \"coefficientTrain\")\n",
    "test_data = apply_triangles_features(test_data, \"trianglesTest\", \"coefficientTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
