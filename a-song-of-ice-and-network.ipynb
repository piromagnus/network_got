{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Neo4j and Networkx\n",
    "## Introduction\n",
    "\n",
    "This notebook aims to compare some algorithms implemented in both Neo4j Graph Data Science and Python's package Networkx.\n",
    "I used the database from https://github.com/mathbeveridge/asoiaf corresponding to interactions between the characters of the books of the saga Song of Ice and Fire by G.R.R Martin.\n",
    "\n",
    "I ran all the tests on my PC with the following configuration :\n",
    "- Intel Core  i5-9300H 2,40 GHz, 4 core, 8 Mo cache memory (turbo 4,10 GHz)\n",
    "- 12 GB RAM \n",
    "\n",
    "## Summary of data\n",
    "The dataset was made according to the books. Two characters are interacting if they are in a 15-words range in a book. The more they are interacting the more the interactions weight is high. \n",
    "\n",
    "Here we consider the 5 first books. There is 2823 relations on 796 nodes which are the characters in the saga.\n",
    "\n",
    "Here are some stats about the interactions of characters.\n",
    "\n",
    "|min|max|avg interactions|stdev|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|1|110|4.620294599017998|8.651722878451903|\n",
    "\n",
    "## How I compare\n",
    "Due to the implementation of Neo4j's graphs, I had considered 2 different mesures of time. One is the first iteration of the algorithm and the other is the average time of the following iterations where the Neo4j's cache memory reduces the computation time.\n",
    "\n",
    "In order to compare networkx and Neo4j, I chose to compare the different implemantion of Betweenness centrality, Page Rank, Label Propagation, BFS and MST.\n",
    "They are different type of algorithms which are implemented both in Neo4j and Networkx. Much of the algorithms are implemented in only one of them.\n",
    "I will compare the average time to compute these algorithms with the same graph. \n",
    "\n",
    "### The Algorithms \n",
    "#### Page Rank\n",
    "This algorithm aims to compute the impact of a node on the graph. I assume Neo4j and Networkx used the same implemented of this algorithms like in this [paper](http://infolab.stanford.edu/~backrub/google.html).\n",
    "I configure damping= 0.85 and max iterations=20 in both softwares.\n",
    "\n",
    "#### Betweenness Centrality\n",
    "This algorithm returns the node which is in the most path between nodes. I don't really know if the implementations are the same.\n",
    "I used the default parameters.\n",
    "\n",
    "#### Label Propagation\n",
    "This algorithm is a community clustering algorithm which creates community of nodes whose have similary labels.\n",
    "I think the implementations are the same because the algorithm is clear as we can see [here](https://neo4j.com/docs/graph-data-science/current/algorithms/label-propagation/).\n",
    "I also used default parameters.\n",
    "\n",
    "#### BFS\n",
    "This algorithm is a classic in graph analysis. I assume both implementations are equivalent. \n",
    "I limit the depth at 5 nodes and start at the node `Jon Snow`.\n",
    "\n",
    "#### MST\n",
    "It is also a classic algorithm. \n",
    "Neo4j used Prim's algorithm and Networkx used Kruskal's one. The complexity is similar between the two algorithms.\n",
    "I used default parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the GOT's Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "table=pd.read_csv('./data/data/asoiaf-all-edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph(name=\"Game of Networks\")\n",
    "n=len(table['Source'])\n",
    "for i in range(n):\n",
    "    G.add_edge(table['Source'][i],table['Target'][i],weight=table['weight'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networkx's tests\n",
    "\n",
    "### Betweenness Centrality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6449413061141969\n"
     ]
    }
   ],
   "source": [
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    nx.betweenness_centrality(G)\n",
    "    b=time()\n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page rank (unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09266203880310059\n"
     ]
    }
   ],
   "source": [
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    nx.pagerank(G,alpha=0.85,max_iter=20,weight=None)\n",
    "    b=time()\n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank (weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1326475238800049\n"
     ]
    }
   ],
   "source": [
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    nx.pagerank(G,alpha=0.85,max_iter=20,weight='weight')\n",
    "    b=time()\n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.189708709716797e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    c=nx.algorithms.community.label_propagation.label_propagation_communities(G)\n",
    "    b=time() \n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Minimum Spanning Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008865909576416016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    nx.minimum_spanning_tree(G)\n",
    "    b=time() \n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1709671020507814e-07\n",
      "[1.9073486328125e-06, 1.1920928955078125e-06, 4.76837158203125e-07, 2.384185791015625e-07, 2.384185791015625e-07]\n"
     ]
    }
   ],
   "source": [
    "liste=[]\n",
    "for i in range(100):\n",
    "    a=time()\n",
    "    t= nx.bfs_edges(G,\"Jon-Snow\",depth_limit=5)\n",
    "    b=time() \n",
    "    liste.append(b-a)\n",
    "print(sum(liste)/100)\n",
    "print(liste[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests Neo4j (ms)\n",
    "This test were not really automated because I wanted to pass through the cache memory in order to have to really time of algorithms. Therefore I had to restart the server between each test. That is why there not has much data as networkx. However, I think this is enough to have a decent overview of the capacity of each one.\n",
    "\n",
    "### Code used:\n",
    "#### Graph in memory\n",
    "```\n",
    "call gds.graph.create(\"G\",\"Character\",\"Interacts\",\n",
    "{\n",
    "        relationshipProperties: 'weight'\n",
    "    })\n",
    "```\n",
    "\n",
    "#### Betweenness centrality\n",
    "```\n",
    " CALL gds.alpha.betweenness.stream({\n",
    "nodeQuery: 'MATCH (p) RETURN id(p) AS id',\n",
    "  relationshipQuery: 'MATCH (p1)-[]-(p2) RETURN id(p1) AS source, id(p2) AS target'\n",
    "})\n",
    "YIELD nodeId,centrality\n",
    "return gds.util.asNode(nodeId).name as user,centrality\n",
    "order by centrality DESC limit 1\n",
    "```\n",
    "#### Page rank (unweighted)\n",
    "```\n",
    "CALL gds.pageRank.stream('G',{maxIterations:20, dampingFactor:0.85})\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name AS name, score\n",
    "ORDER BY score DESC, name ASC limit 1\n",
    "```\n",
    "#### Page rank (weighted)\n",
    "```\n",
    "CALL gds.pageRank.stream('got',{maxIterations:20, dampingFactor:0.85,relationshipWeightProperty: 'weight'})\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name AS name, score\n",
    "ORDER BY score DESC, name ASC limit 1\n",
    "```\n",
    "\n",
    "####  Label Propagation\n",
    "```\n",
    "CALL gds.labelPropagation.stream('G'})\n",
    "YIELD nodeId, communityId AS Community\n",
    "RETURN gds.util.asNode(nodeId).name AS Name, Community\n",
    "ORDER BY Community, Name limit 1 \n",
    "```\n",
    "\n",
    "#### BFS\n",
    "```\n",
    "MATCH (a:Character{name:'Jon Snow'})\n",
    "WITH id(a) AS startNode\n",
    "CALL gds.alpha.bfs.stream('G', {startNode: startNode,maxDepth :5})\n",
    "YIELD path\n",
    "UNWIND [ n in nodes(path) | n.name] AS name\n",
    "RETURN name\n",
    "ORDER BY name limit 1\n",
    "```\n",
    "\n",
    "#### MST\n",
    "```\n",
    "MATCH (n:Character {name: 'Jon Snow'})\n",
    "CALL gds.alpha.spanningTree.minimum.write({\n",
    "  nodeProjection: 'Character',\n",
    "  relationshipProjection: {\n",
    "  \tInteracts: {\n",
    "    \ttype :'Interacts',\n",
    "   \t \tproperties: 'weight',\n",
    "    \torientation: 'UNDIRECTED'\n",
    "    \t}\n",
    "    },\n",
    "    startNodeId: id(n),\n",
    "    relationshipWeightProperty: 'weight',\n",
    "    writeProperty: 'MINST',\n",
    "    weightWriteProperty: 'writeCost'\n",
    "})\n",
    "YIELD createMillis, computeMillis, writeMillis, effectiveNodeCount\n",
    "RETURN createMillis, computeMillis, writeMillis, effectiveNodeCount;\n",
    "```\n",
    "\n",
    "### Raw results: \n",
    "betweenness #1 (ms) : 354,90,67,76,59,85,55,61,84,58,69\n",
    "\n",
    "page rank #1 (ms) : 327,202,166, crash\n",
    "\n",
    "betweenness #2 (ms) : 288,95,85,61,65,69,68,69\n",
    "\n",
    "page rank #2 (ms) : 294,191,146\n",
    "\n",
    "page rank #3 (ms) : 451, 241, 154,\n",
    "\n",
    "page rank (weighted) : 347,215, 122,123\n",
    "\n",
    "page rank (weighted) : 343,201, 138,114\n",
    "page rank (weighted) : 284,233, 125,110\n",
    "\n",
    "label propagation #1 (ms) : 230, 89,88,68,47,62,47,43,47\n",
    "\n",
    "label propagation #2 (ms) : 120, 62,51,33,27,38,30\n",
    "\n",
    "label propagation #3 (ms) : 170, 74, 64,79,44,49,47,46,67,\n",
    "\n",
    "BFS (graph in memory) : environ 37;38,7;38,5 seconds for  max depth=5\n",
    "\n",
    "MST :454,42 \n",
    "\n",
    "MST(with graph projection during the algo) : , 1100, 1255,\n",
    "\n",
    "MST (others first iterations) :488,483, 583,\n",
    "\n",
    "MST:  620,66,57,53,60,46\n",
    "\n",
    "## Synthesis\n",
    "Algorithm | Time Neo4j (s) | Time Networkx(s)\n",
    ":-: | :-: | :-:\n",
    "Betweenness centrality | 0,32 (0,08 after) | 1,6\n",
    "Page rank (unweighted) | 0,36 (0,1 after) | 0,09\n",
    "Page rank(weighted) | 0,36 (0,1 after) | 0,12\n",
    "Label Propagation | 0,17 (0,05 after) | 1e-6  (1e-5 for the first one)\n",
    "Breadth First Search | 38 | 3e-7 (2e-6 for the 2 first ones)\n",
    "Minimum spanning tree | 0,52 (0,06 after)| 7e-3 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "It is hard to have a clear decision because there is huge gap for either software. Most of the time Networkx is far better than neo4j. But is some case (Betweenness and Page rank) Neo4j is better or  getting even better after the first iteration due to the use of a cache. We also can see that weighted or unweighted Page rank doesn't change anything for neo4j but changes a bit for networkx. (This precisition is lower for neo4j)\n",
    "However, there is a huge gap between Neo4j and Network regarding to BFS's algorithm (1e8 order of magnitude...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
