{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction on Game of Thrones Graph\n",
    "This is a notebook based on the Chapiter 8 from O'Reilly's Graph Algorithms book freely available here : https://neo4j.com/graph-algorithms-book/.\n",
    "My dataset is the Game of Thrones dataset from  https://github.com/mathbeveridge/asoiaf with all details [here](https://github.com/piromagnus/network_got/blob/master/a-song-of-ice-and-network.ipynb).\n",
    "\n",
    "This notebook aims to create a link prediction model for this dataset. We will try to improve it at each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "This notebook requires [Spark](http://spark.apache.org/downloads.html) and pip3 in order to work.\n",
    "\n",
    "You also need to set up the `SPARK_HOME` with the location of Spark's folder.\n",
    "\n",
    "You also need to have a Neo4j's graph at localhost with the following credential. (You can modify them)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred=(\"neo4j\",\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py2neo in /home/piromagnus/.local/lib/python3.8/site-packages (4.3.0)\n",
      "Requirement already satisfied: pyspark in /home/piromagnus/.local/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: findspark in /home/piromagnus/.local/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.23 in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (1.24.3)\n",
      "Requirement already satisfied: colorama in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (0.4.3)\n",
      "Requirement already satisfied: pytz in /usr/lib/python3/dist-packages (from py2neo) (2019.3)\n",
      "Requirement already satisfied: neobolt~=1.7.12 in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (1.7.17)\n",
      "Requirement already satisfied: prompt-toolkit~=2.0.7 in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (2.0.10)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from py2neo) (2019.11.28)\n",
      "Requirement already satisfied: neotime~=1.7.4 in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (1.7.4)\n",
      "Requirement already satisfied: click==7.0 in /home/piromagnus/.local/lib/python3.8/site-packages (from py2neo) (7.0)\n",
      "Requirement already satisfied: pygments~=2.3.1 in /usr/lib/python3/dist-packages (from py2neo) (2.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/piromagnus/.local/lib/python3.8/site-packages (from pyspark) (0.10.9)\n",
      "Requirement already satisfied: wcwidth in /usr/lib/python3/dist-packages (from prompt-toolkit~=2.0.7->py2neo) (0.1.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from prompt-toolkit~=2.0.7->py2neo) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install py2neo pyspark findspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the GoT's Graph\n",
    "Run the following Cypher requests :\n",
    "```cypher\n",
    "Load CSV with HEADERS FROM \"https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-all-edges.csv\" as row\n",
    "MATCH (c:Character {id:row.Target})\n",
    "MATCH (d:Character {id:row.Source})\n",
    "MERGE (c)-[:Interacts{weight:toInteger(row.weight)}]-(d)\n",
    "```\n",
    "```cypher\n",
    "Load CSV with HEADERS FROM \"https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-book1-edges.csv\" as row\n",
    "MATCH (c:Character {id:row.Target})\n",
    "MATCH (d:Character {id:row.Source})\n",
    "MERGE (c)-[:Interacts_early{weight:toInteger(row.weight)}]-(d)\n",
    "```\n",
    "\n",
    "```cypher\n",
    "Load CSV with HEADERS FROM \"https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-book2-edges.csv\" as row\n",
    "MATCH (c:Character {id:row.Target})\n",
    "MATCH (d:Character {id:row.Source})\n",
    "MERGE (c)-[:Interacts_early{weight:toInteger(row.weight)}]-(d)\n",
    "```\n",
    "\n",
    "```cypher\n",
    "Load CSV with HEADERS FROM \"https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-book3-edges.csv\" as row\n",
    "MATCH (c:Character {id:row.Target})\n",
    "MATCH (d:Character {id:row.Source})\n",
    "MERGE (c)-[:Interacts_early{weight:toInteger(row.weight)}]-(d)\n",
    "```\n",
    "\n",
    "```cypher\n",
    "Load CSV with HEADERS FROM \"https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-book45-edges.csv\" as row\n",
    "MATCH (c:Character {id:row.Target})\n",
    "MATCH (d:Character {id:row.Source})\n",
    "MERGE (c)-[:Interacts_late{weight:toInteger(row.weight)}]-(d)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from collections import Counter\n",
    "from cycler import cycler\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection and creation of the learning dataset\n",
    "We are going to connect this notebook to the GoT's graph.\n",
    "\n",
    "Then we are going to split relationships in 2 set, one for training and the other for testing. \n",
    "I chose to use the 3 first books for training the model and the 2 last ones for the test. (ratio is 58/42 of the relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost\", auth=cred)\n",
    "def down_sample(df):\n",
    "    copy = df.copy()\n",
    "    zero = Counter(copy.label.values)[0]\n",
    "    un = Counter(copy.label.values)[1]\n",
    "    n = zero - un\n",
    "    copy = copy.drop(copy[copy.label == 0].sample(n=n, random_state=1).index)\n",
    "    return copy.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "Failed to establish connection to ('127.0.0.1', 7687) (reason [Errno 111] Connection refused)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(resolved_address, **config)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mlog_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[#0000]  C: <OPEN> %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1eae117ebc9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find positive examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_existing_links = graph.run(\"\"\"\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mMATCH\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCharacter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mInteracts_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCharacter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRETURN\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\").to_data_frame()# Find negative examples\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseparate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             return Cursor(self.connector.run(statement=cypher,\n\u001b[0m\u001b[1;32m    824\u001b[0m                                              \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                                              \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py2neo/internal/connectors.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, statement, parameters, tx, graph, keys, entities)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_in_tx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py2neo/internal/connectors.py\u001b[0m in \u001b[0;36m_run_1\u001b[0;34m(self, statement, parameters, graph, keys, entities)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mhydrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackStreamHydrator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mdehydrated_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhydrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdehydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, access_mode)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36macquire_direct\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcan_create_new_connection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_error_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py2neo/internal/connectors.py\u001b[0m in \u001b[0;36mconnector\u001b[0;34m(address_, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             return connect(address_, auth=cx_data[\"auth\"],\n\u001b[0m\u001b[1;32m    227\u001b[0m                            encrypted=cx_data[\"secure\"], **kwargs)\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(address, **config)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to resolve addresses for %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mlast_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(address, **config)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mder_encoded_server_certificate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_secure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity_plan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mder_encoded_server_certificate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(resolved_address, **config)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mlog_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[#0000]  C: <CLOSE> %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to establish connection to {!r} (reason {})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: Failed to establish connection to ('127.0.0.1', 7687) (reason [Errno 111] Connection refused)"
     ]
    }
   ],
   "source": [
    "# Find positive examples\n",
    "train_existing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)-[:Interacts_early]->(b:Character)\n",
    "RETURN id(a) AS node1, id(b) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()# Find negative examples\n",
    "train_missing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)\n",
    "WHERE (a)-[:Interacts_early]-()\n",
    "MATCH (a)-[:Interacts_early*2..3]-(other)\n",
    "WHERE not((a)-[:Interacts_early]-(other))\n",
    "RETURN id(a) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()# Remove duplicates\n",
    "train_missing_links = train_missing_links.drop_duplicates()\n",
    "training_df = train_missing_links.append(train_existing_links, ignore_index=True)\n",
    "training_df['label'] = training_df['label'].astype('category')\n",
    "training_df = down_sample(training_df)\n",
    "training_data = spark.createDataFrame(training_df)\n",
    "\n",
    "test_existing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)-[:Interacts_late]->(b:Character)\n",
    "RETURN id(a) AS node1, id(b) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()# Find negative examples\n",
    "test_missing_links = graph.run(\"\"\"\n",
    "MATCH (a:Character)\n",
    "WHERE (a)-[:Interacts_late]-()\n",
    "MATCH (a)-[:Interacts_late*2..3]-(other)\n",
    "WHERE not((a)-[:Interacts_late]-(other))\n",
    "RETURN id(a) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()# Remove duplicates\n",
    "test_missing_links = test_missing_links.drop_duplicates()\n",
    "test_df = test_missing_links.append(test_existing_links, ignore_index=True)\n",
    "test_df['label'] = test_df['label'].astype('category')\n",
    "test_df = down_sample(test_df)\n",
    "test_data = spark.createDataFrame(test_df)\n",
    "training_data.groupby(\"label\").count().show()\n",
    "test_data.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1849/(1849+1329)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(fields):\n",
    "    assembler = VectorAssembler(inputCols=fields, outputCol=\"features\")\n",
    "    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",\n",
    "                                numTrees=30, maxDepth=10)\n",
    "    return Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the first feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_graphy_training_features(data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    size([(p1)-[:Interacts_early]-(a)-\n",
    "    [:Interacts_early]-(p2) | a]) AS CommonInteractions,\n",
    "    size((p1)-[:Interacts_early]-()) * size((p2)-\n",
    "    [:Interacts_early]-()) AS prefAttachment,\n",
    "    size(apoc.coll.toSet(\n",
    "    [(p1)-[:Interacts_early]-(a) | id(a)] +\n",
    "    [(p2)-[:Interacts_early]-(a) | id(a)]\n",
    "    )) AS totalNeighbors\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "    for row in data.collect()]\n",
    "    features = spark.createDataFrame(graph.run(query,\n",
    "                                               {\"pairs\": pairs}).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "def apply_graphy_test_features(data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    size([(p1)-[:Interacts]-(a)-[:Interacts]-(p2) | a]) AS CommonInteractions,\n",
    "    size((p1)-[:Interacts]-()) * size((p2)-[:Interacts]-())\n",
    "    AS prefAttachment,\n",
    "    size(apoc.coll.toSet(\n",
    "    [(p1)-[:Interacts]-(a) | id(a)] + [(p2)-[:Interacts]-(a) | id(a)]\n",
    "    )) AS totalNeighbors\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "    for row in data.collect()]\n",
    "    features = spark.createDataFrame(graph.run(query,\n",
    "                                               {\"pairs\": pairs}).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "\n",
    "training_data = apply_graphy_training_features(training_data)\n",
    "test_data = apply_graphy_test_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the following graph, we can see two persons who have many commons Interactions are more likely to interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 7), sharey=True)\n",
    "charts = [(1, \"have interacted\"), (0, \"haven't interacted\")]\n",
    "for index, chart in enumerate(charts):\n",
    "    label, title = chart\n",
    "    filtered = training_data.filter(training_data[\"label\"] == label)\n",
    "    interactions = filtered.toPandas()[\"CommonInteractions\"]\n",
    "    histogram =interactions.value_counts().sort_index()\n",
    "    histogram /= float(histogram.sum())\n",
    "    histogram.plot(kind=\"bar\", x='Common Interactions', color=\"darkblue\",\n",
    "    ax=axs[index], title=f\"Character who {title} (label={label})\")\n",
    "    axs[index].xaxis.set_label_text(\"Common Interactions\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of model\n",
    "\n",
    "Here is a basic model based on common interactions in order to predict the future interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(fields, training_data):\n",
    "    pipeline = create_pipeline(fields)\n",
    "    model = pipeline.fit(training_data)\n",
    "    return model\n",
    "\n",
    "basic_model = train_model([\"CommonInteractions\"], training_data)\n",
    "\n",
    "eval_df = spark.createDataFrame(\n",
    "        [(0,), (1,), (2,), (10,), (100,)],\n",
    "        ['CommonInteractions'])\n",
    "\n",
    "\n",
    "(basic_model.transform(eval_df)\n",
    "    .select(\"CommonInteractions\", \"probability\", \"prediction\")\n",
    "    .show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model.\n",
    "We are using 4 differents metrics in order to evaluate the model.\n",
    "\n",
    "\n",
    "- Accuracy : The fraction of predictions our model gets right, or the total number of correct predictions divided by the total number of predictions. Note that accuracy alone can be misleading, especially when our data is unbalanced. For example, if we have a dataset containing 95 cats and 5 dogs and our model predicts that every image is a cat weâ€™ll have a 95% accuracy score despite correctly identifying none of the dogs. The formula is $\\dfrac{TruePositives+TrueNegatives}{TotalPrediction}$\n",
    "\n",
    "- Precision :The proportion of positive identifications that are correct. A low precision score indicates more false positives. A model that produces no false positives has a precision of 1.0. It is the metric which highlight if the model can predict well the links that already exists. The formula is $\\dfrac{TruePositives}{TruePositives+FalsePositives}$\n",
    "\n",
    "- Recall(true positive rate) :The proportion of actual positives that are identified correctly. A low recall score indicates more false negatives. A model that produces no false negatives has a recall of 1.0. This metric shows if the model predicts well the linked that did not existed before. The formula is $\\dfrac{TruePositives}{TruePositives+FalseNegatives}$\n",
    "\n",
    "\n",
    "- Receiver operating characteristic  (ROC) curve is a plot of the Recall (true positive rate) against the False Positive rate at different classification thresholds. The area under the curve (AUC) measures the two-dimensional area underneath the ROC curve from an X-Y axis (0,0) to (1,1) where the false positive rate is defined by $\\dfrac{FalsePositives}{FalsePositives+TrueNegatives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    # Execute the model against the test set\n",
    "    predictions = model.transform(test_data)\n",
    "    # Compute true positive, false positive, false negative counts\n",
    "    tp = predictions[(predictions.label == 1) &\n",
    "        (predictions.prediction == 1)].count()\n",
    "    fp = predictions[(predictions.label == 0) &\n",
    "                     (predictions.prediction == 1)].count()\n",
    "    fn = predictions[(predictions.label == 1) &\n",
    "                     (predictions.prediction == 0)].count()\n",
    "    # Compute recall and precision manually\n",
    "    recall = float(tp) / (tp + fn)\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    # Compute accuracy using Spark MLLib's binary classification evaluator\n",
    "    accuracy = BinaryClassificationEvaluator().evaluate(predictions)\n",
    "    # Compute false positive rate and true positive rate using sklearn functions\n",
    "    labels = [row[\"label\"] for row in predictions.select(\"label\").collect()]\n",
    "    preds = [row[\"probability\"][1] for row in predictions.select\n",
    "             (\"probability\").collect()]\n",
    "    fpr, tpr, threshold = roc_curve(labels, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return { \"fpr\": fpr, \"tpr\": tpr, \"roc_auc\": roc_auc, \"accuracy\": accuracy,\n",
    "            \"recall\": recall, \"precision\": precision }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    results = {k: v for k, v in results.items() if k not in [\"fpr\", \"tpr\", \"roc_auc\"]}\n",
    "    return pd.DataFrame({\"Measure\": list(results.keys()),\n",
    "                         \"Score\": list(results.values())})\n",
    "\n",
    "basic_results = evaluate_model(basic_model, test_data)\n",
    "display_results(basic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_plot():\n",
    "    plt.style.use('classic')\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.rc('axes', prop_cycle=(cycler('color',\n",
    "                                      ['r', 'g', 'b', 'c', 'm', 'y', 'k'])))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random score (AUC = 0.50)')\n",
    "    return plt, fig\n",
    "\n",
    "def add_curve(plt, title, fpr, tpr, roc):\n",
    "    plt.plot(fpr, tpr, label=f\"{title} (AUC = {roc:0.2})\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",basic_results[\"fpr\"], basic_results[\"tpr\"], basic_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is quite performant but there is still a large amount of mistakes. We will improve it.\n",
    "\n",
    "## A more complex model with 3 features\n",
    "When we print the stats on 3 features for the people who have interacted and those who don't we can see the character who have interacted have a higher mean for the 3 following features.\n",
    "- Common Interactions is the number of potential triangles between two character. This is the idea that two characters who have interacted with the same person are more likely to interact.\n",
    "- Preferential attachment is a score computed for each pair of characters by multiplying the number of interactions each has. This idea behind it is the fact that someone who interact with many people is more likely to interact with someone new.\n",
    "- The total union of neighbors is the number of interactions each character has.\n",
    "\n",
    "In the following stats, we can see that people who have interacted have much more commons interactions that those who don't. This reveals that this can be a useful feature. On the opposite, the total Neighbors is not really relevent because both people who have interacted and who don't have almost the same amount of total neighbors.(if we consider the standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data.filter(training_data[\"label\"]==1)\n",
    "    .describe()\n",
    "    .select(\"summary\", \"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\")\n",
    "    .show())\n",
    "(training_data.filter(training_data[\"label\"]==0)\n",
    "    .describe()\n",
    "    .select(\"summary\", \"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\")\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\"]\n",
    "graphy_model = train_model(fields, training_data)\n",
    "\n",
    "graphy_results = evaluate_model(graphy_model, test_data)\n",
    "display_results(graphy_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",\n",
    "          basic_results[\"fpr\"], basic_results[\"tpr\"],\n",
    "                              basic_results[\"roc_auc\"])\n",
    "add_curve(plt, \"Graphy\",\n",
    "          graphy_results[\"fpr\"], graphy_results[\"tpr\"],\n",
    "          graphy_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics are better but precision and recall are still to low.\n",
    "## Which features are important ?\n",
    "Let see which feature is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(fields, feature_importances):\n",
    "    df = pd.DataFrame({\"Feature\": fields, \"Importance\": feature_importances})\n",
    "    df = df.sort_values(\"Importance\", ascending=False)\n",
    "    ax = df.plot(kind='bar', x='Feature', y='Importance', legend=None)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = graphy_model.stages[-1]\n",
    "plot_feature_importance(fields, rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Commons Interactions is the more important features and total neighbors is the less relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a decision tree (WIP package on jupyter...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from spark_tree_plotting import export_graphviz\n",
    "dot_string = export_graphviz(rf_model.trees[0],\n",
    "                             featureNames=fields, categoryNames=[], classNames=[\"True\", \"False\"],\n",
    "                             filled=True, roundedCorners=True, roundLeaves=True)\n",
    "with open(\"/tmp/rf.dot\", \"w\") as file:\n",
    "    file.write(dot_string)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new features: triangle and clusters\n",
    "Here we are going to add some other features: triangle and cluster coefficient. \n",
    "The idea is the fact that someone who are in a large amount of triangle are more likely to \"close\" the other triangle.\n",
    "And it is the same with cluster coefficient. If someone has a high cluster coefficient is his more likely to meet someone else and widen the local cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to call some functions in Neo4j.\n",
    "\n",
    "```cypher\n",
    "call gds.graph.create(\"G\",\"Character\",\n",
    "{\n",
    "\tInteracts : {\n",
    "    \ttype:\"Interacts\",\n",
    "        properties: 'weight',\n",
    "        orientation:'UNDIRECTED'\n",
    "    }\n",
    "    })\n",
    "```\n",
    "    \n",
    "```cypher\n",
    "CALL gds.triangleCount.write(\"G\", {\n",
    "writeProperty:'trianglesTest'})\n",
    "```\n",
    "```cypher\n",
    "CALL gds.localClusteringCoefficient.write(\"G\", {\n",
    "writeProperty:'coefficientTest'})\n",
    "```\n",
    "\n",
    "\n",
    "```cypher\n",
    "call gds.graph.create(\"G_ea\",\"Character\",\n",
    "{\n",
    "\tInteracts_early : {\n",
    "    \ttype:\"Interacts_early\",\n",
    "        properties: 'weight',\n",
    "        orientation:'UNDIRECTED'\n",
    "    }\n",
    "    })\n",
    "```\n",
    "\n",
    "```cypher\n",
    "CALL gds.triangleCount.write(\"G_ea\", {\n",
    "writeProperty:'trianglesTrain'})\n",
    "```\n",
    "\n",
    "```cypher\n",
    "CALL gds.localClusteringCoefficient.write(\"G\", {\n",
    "writeProperty:'coefficientTrain'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_triangles_features(data, triangles_prop, coefficient_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "            pair.node2 AS node2,\n",
    "            apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]])\n",
    "            AS minTriangles,\n",
    "            apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]])\n",
    "            AS maxTriangles,\n",
    "            apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]])\n",
    "            AS minCoefficient,\n",
    "            apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]])\n",
    "            AS maxCoefficient\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"pairs\": [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]}\n",
    "                            for row in data.collect()],\n",
    "        \"trianglesProp\": triangles_prop,\n",
    "        \"coefficientProp\": coefficient_prop\n",
    "    }\n",
    "    features = spark.createDataFrame(graph.run(query, params).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "\n",
    "training_data = apply_triangles_features(training_data, \"trianglesTrain\", \"coefficientTrain\")\n",
    "test_data = apply_triangles_features(test_data, \"trianglesTest\", \"coefficientTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data.filter(training_data[\"label\"]==1)\n",
    ".describe()\n",
    ".select(\"summary\", \"minTriangles\", \"maxTriangles\",\n",
    "\"minCoefficient\", \"maxCoefficient\")\n",
    ".show())\n",
    "(training_data.filter(training_data[\"label\"]==0)\n",
    ".describe()\n",
    ".select(\"summary\", \"minTriangles\", \"maxTriangles\", \"minCoefficient\",\n",
    "\"maxCoefficient\")\n",
    ".show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the coefficient does not seem relevant because the data from interacting people and non-interacting people are similar. Triangle has more potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\",\n",
    "            \"minTriangles\", \"maxTriangles\", \"minCoefficient\", \"maxCoefficient\"]\n",
    "triangle_model = train_model(fields, training_data)\n",
    "triangle_results = evaluate_model(triangle_model, test_data)\n",
    "display_results(triangle_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",\n",
    "basic_results[\"fpr\"], basic_results[\"tpr\"], basic_results[\"roc_auc\"])\n",
    "add_curve(plt, \"Graphy\",\n",
    "graphy_results[\"fpr\"], graphy_results[\"tpr\"],\n",
    "graphy_results[\"roc_auc\"])\n",
    "add_curve(plt, \"Triangles\",\n",
    "triangle_results[\"fpr\"], triangle_results[\"tpr\"],\n",
    "triangle_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models is becoming better but the improvement is not impressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = triangle_model.stages[-1]\n",
    "plot_feature_importance(fields, rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see as suggested but the data stats that Triangles are more relevant that coefficient but not as relevant as the 3 first ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection\n",
    "Here we are using two algorithms to find communities in the graph. The first one is label propagation and the second is Louvain which gives us the intermediate communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cypher\n",
    "CALL gds.louvain.stream(\"G\",{includeIntermediateCommunities:True})\n",
    "YIELD nodeId, communityId, intermediateCommunityIds\n",
    "WITH gds.util.asNode(nodeId) AS node, intermediateCommunityIds[0] AS smallestCommunity\n",
    "SET node.louvainTest = smallestCommunity\n",
    "```\n",
    "```cypher\n",
    "Call gds.labelPropagation.write(\"G\", {writeProperty:\"partitionTest\"})\n",
    " ```\n",
    "\n",
    "```cypher\n",
    "CALL gds.louvain.stream(\"G_ea\",{includeIntermediateCommunities:True})\n",
    "YIELD nodeId, communityId, intermediateCommunityIds\n",
    "WITH gds.util.asNode(nodeId) AS node, intermediateCommunityIds[0] AS smallestCommunity\n",
    "SET node.louvainTrain = smallestCommunity\n",
    "```\n",
    "```cypher\n",
    "Call gds.labelPropagation.write(\"G_ea\", {writeProperty:\"partitionTrain\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_community_features(data, partition_prop, louvain_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "            pair.node2 AS node2,\n",
    "            CASE WHEN p1[$partitionProp] = p2[$partitionProp] THEN\n",
    "            1 ELSE 0 END AS samePartition,\n",
    "            CASE WHEN p1[$louvainProp] = p2[$louvainProp] THEN\n",
    "            1 ELSE 0 END AS sameLouvain\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"pairs\": [{\"node1\": row[\"node1\"], \"node2\": row[\"node2\"]} for\n",
    "                            row in data.collect()],\n",
    "        \"partitionProp\": partition_prop,\n",
    "        \"louvainProp\": louvain_prop\n",
    "    }\n",
    "    features = spark.createDataFrame(graph.run(query, params).to_data_frame())\n",
    "    return data.join(features, [\"node1\", \"node2\"])\n",
    "training_data = apply_community_features(training_data, \"partitionTrain\", \"louvainTrain\")\n",
    "test_data = apply_community_features(test_data, \"partitionTest\", \"louvainTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 7), sharey=True)\n",
    "charts = [(1, \"have interacted\"), (0, \"haven't interacted\")]\n",
    "for index, chart in enumerate(charts):\n",
    "    label, title = chart\n",
    "    filtered = training_data.filter(training_data[\"label\"] == label)\n",
    "    values = (filtered.withColumn('samePartition',\n",
    "            F.when(F.col(\"samePartition\") == 0, \"False\")\n",
    "            .otherwise(\"True\"))\n",
    "            .groupby(\"samePartition\")\n",
    "            .agg(F.count(\"label\").alias(\"count\"))\n",
    "            .select(\"samePartition\", \"count\")\n",
    "            .toPandas())\n",
    "    values.set_index(\"samePartition\", drop=True, inplace=True)\n",
    "    values.plot(kind=\"bar\", ax=axs[index], legend=None,\n",
    "                title=f\"Characters who {title} (label={label})\")\n",
    "    axs[index].xaxis.set_label_text(\"Same Partition\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this two graphs, we can guess that these features will be relevant because the differences between interacting and non-interacting people considering the communities are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 7), sharey=True)\n",
    "charts = [(1, \"have Interacted\"), (0, \"haven't interacted\")]\n",
    "for index, chart in enumerate(charts):\n",
    "    label, title = chart\n",
    "    filtered = training_data.filter(training_data[\"label\"] == label)\n",
    "    values = (filtered.withColumn('sameLouvain',\n",
    "            F.when(F.col(\"sameLouvain\") == 0, \"False\")\n",
    "            .otherwise(\"True\"))\n",
    "            .groupby(\"sameLouvain\")\n",
    "            .agg(F.count(\"label\").alias(\"count\"))\n",
    "            .select(\"sameLouvain\", \"count\")\n",
    "            .toPandas())\n",
    "    values.set_index(\"sameLouvain\", drop=True, inplace=True)\n",
    "    values.plot(kind=\"bar\", ax=axs[index], legend=None,\n",
    "    title=f\"Characted who {title} (label={label})\")\n",
    "    axs[index].xaxis.set_label_text(\"Same Louvain\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CommonInteractions\", \"prefAttachment\", \"totalNeighbors\", \"minTriangles\", \"maxTriangles\", \"minCoefficient\", \"maxCoefficient\", \"samePartition\", \"sameLouvain\"]\n",
    "community_model = train_model(fields, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_results = evaluate_model(community_model, test_data)\n",
    "display_results(community_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig = create_roc_plot()\n",
    "add_curve(plt, \"Common Interactions\",basic_results[\"fpr\"], basic_results[\"tpr\"], basic_results[\"roc_auc\"])\n",
    "#add_curve(plt, \"Graphy\",graphy_results[\"fpr\"], graphy_results[\"tpr\"], graphy_results[\"roc_auc\"])\n",
    "#add_curve(plt, \"Triangles\", triangle_results[\"fpr\"], triangle_results[\"tpr\"], triangle_results[\"roc_auc\"])\n",
    "add_curve(plt, \"Full model\", community_results[\"fpr\"], community_results[\"tpr\"], community_results[\"roc_auc\"])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = community_model.stages[-1]\n",
    "plot_feature_importance(fields, rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model is still better but not perfect. However we can see that louvain is really performant where samePartition is not really."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We built a model in order to predict the future interactions in the GoT's graphs. The model is not perfect there is still about 10% of error but this can be due to the low amount of data we considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
